data= read.csv("~/MLR_Project/TourismData.csv", sep = ";")
head(data)
summary(data) #checked the NA rows etc.


# 2020_2 verisini ayƒ±rma (Leave-One-Out)
data_test = subset(data, TimeIndex == "2020_2")
data_train = subset(data, !(TimeIndex == "2020_2"))


##### TOURISM INCOME PREDICTION

install.packages("caret")
install.packages("xgboost")

##### DATA_TRAIN - DATA_TEST: NUMERIC VERILER HEPSƒ∞
#### DATA_TRAIN2 - DATA_TEST2: YEAR VE QUARTER FACTOR KATEGORIK, TEST2 INCOME LINEAR, CATEGORY RATIO
### DATA_TEST3: KATEGORILER VE INCOME MODELSƒ∞Z SADECE TRAINDEN TURIST/ X ORANIYLA BULUNDU. 

### year ve quarter factor olan diƒüer verisetlerini olu≈ütur
data_train2 = data_train
data_test2 = data_test
data_train2$Quarter <- as.factor(data_train$Quarter)
data_test2$Quarter <- as.factor(data_test$Quarter)

data_train2$Year <- as.factor(data_train$Year)
data_test2$Year <- as.factor(data_test$Year)

str(data_train2)
str(data_test)

# Fakt√∂r seviyelerini e≈üitleme
data_train2$Year <- factor(data_train2$Year, levels = unique(data_train2$Year))
data_train2$Quarter <- factor(data_train2$Quarter, levels = unique(data_train2$Quarter))

data_test2$Year <- factor(data_test2$Year, levels = levels(data_train2$Year))
data_test2$Quarter <- factor(data_test2$Quarter, levels = levels(data_train2$Quarter))


### MULTIPLE LINEAR numeric
lm_model <- lm(Total_Income ~ TouristNumber + Year + Quarter, data = data_train)
lm_pred <- predict(lm_model, newdata = data_test)

# Multiple Linear Regression (Kategorik)
lm_factor_model <- lm(Total_Income ~ TouristNumber + Year + Quarter, data = data_train2)
lm_factor_pred <- predict(lm_factor_model, newdata = data_test2)

# Random Forest
library(randomForest)
rf_model <- randomForest(Total_Income ~ TouristNumber + Year + Quarter, data = data_train2, ntree = 500)
rf_pred <- predict(rf_model, newdata = data_test2)

# Tahmin Sonu√ßlarƒ±
cat("Multiple Linear Model (Kategorik) Tahmini:", lm_factor_pred, "\n" , 
    "Random Forest Tahmini:", rf_pred, "\n",
    "Multiple Linear Model (numeric) Tahmini:", lm_pred, "\n")  ## random forest best pred.


# Performance Metric Calculation Function
mae <- function(actual, predicted) {
  mean(abs(actual - predicted))}

lm_mae <- mae(data_train$Total_Income, lm_pred)

rf_mae <- mae(data_train2$Total_Income, rf_pred)

lm_fac_mae <- mae(data_train2$Total_Income,lm_factor_pred)

# Sonu√ßlarƒ± Kar≈üƒ±la≈ütƒ±rma Tablosu
results <- data.frame(
  Model = c("Linear Regression", "Random Forest", "Lin. Reg. Factor"),
  MAE = c(lm_mae, rf_mae, lm_fac_mae))
print(results)

# Multiple lin reg kategorik ile en iyi modelden Total_Income tahminini ekleme
data_test$Total_Income <- lm_factor_pred 

# Total Income deƒüerini Factor olan verisetine de ekleyelim
data_test2$Total_Income <- lm_factor_pred


### üîπ Veriyi Hazƒ±rlama
input_features <- c("TouristNumber", "Total_Income")
output_features <- c("Ind_Expenditure", "Food_Beverage", "Accommodation", 
                     "Health", "Clothes", "Carpet_Rug", "GSM_Expenditure", "Souvenirs")

# üìå Diƒüer Kategorilerin Income √ºzerinden Oransal Tahmini ------ kullanƒ±lmayan kƒ±sƒ±m olailir
category_ratios <- colMeans(data_train2[, output_features] / data_train2$Total_Income, na.rm = TRUE)
# üìå Oranlara G√∂re Tahmin
for (feature in output_features) {
    data_test2[[feature]] <- data_test2$Total_Income * category_ratios[feature]
  }


#### MODELLER TAHMƒ∞Nƒ∞ YERƒ∞NE TURƒ∞ZM INCOME'I TURƒ∞ST SAYISINA ORANININ AVG DEƒûERƒ∞ ƒ∞LE 240K BULDUM.
data_test3= data_test2

category_ratios <-data_train2$Total_Income / data_train2$TouristNumber

data_test3$Total_Income <- data_test3$TouristNumber * mean(category_ratios)
View(data_test3)


### VE BU RATIO ORANIYLA BULUNAN TOURISM INCOME ILE Dƒ∞ƒûERLERƒ∞ ƒ∞√áƒ∞N CATEGORY RATIO YAPIYORUZ
category_ratios <- sapply(output_features, function(feature) {
  mean(data_train2[[feature]] / data_train2$Total_Income, na.rm = TRUE)
})

for (feature in output_features) {
  data_test3[[feature]] <- data_test3$Total_Income * category_ratios[feature]
}

View(data_test3)

plot(Total_Income ~ TouristNumber, data = data_test3)



#### DATA_TOURISM VERƒ∞SETƒ∞YLE T√úM DATAYI Bƒ∞RLE≈ûTƒ∞RDƒ∞M 2020_2 KISMINI EKLEDƒ∞M

targets2 <- c("Total_Income","Food_Beverage", "Accommodation", 
             "Health", "Clothes", "Carpet_Rug", 
             "GSM_Expenditure", "Souvenirs", "Ind_Expenditure")

data_tourism = data
data_tourism[which(data_tourism$TimeIndex == "2020_2"), targets2] <- data_test3[which(data_test3$TimeIndex == "2020_2"), targets2]

View(data_tourism)


#### HER SATIR ƒ∞√áƒ∞N INCOME'A ORANLARINA G√ñRE KATEGORƒ∞LERƒ∞ KENDƒ∞ ARASINDA HIGH-LOW LABELLADIK

targets <- c("Food_Beverage", "Accommodation", 
             "Health", "Clothes", "Carpet_Rug", 
             "GSM_Expenditure", "Souvenirs", "Ind_Expenditure")

data_tourism_hl <- data_tourism

# Kategori oranlarƒ±na g√∂re High/Low belirleme (Her satƒ±r i√ßin)
for (col in targets) {
  # Her satƒ±rda kategoriyi Total_Income'a b√∂lerek oran hesapla
  ratio_values <- data_tourism[[col]] / data_tourism$Total_Income
  
  # Oranlarƒ±n genel ortalama ve standart sapmasƒ±nƒ± hesapla
  mean_ratio <- mean(ratio_values, na.rm = TRUE)
  sd_ratio <- sd(ratio_values, na.rm = TRUE)
  
  # Z-score hesapla ve High/Low etiketle
  z_scores <- (ratio_values - mean_ratio) / sd_ratio
  data_tourism_hl[[paste0(col, "_Level")]] <- ifelse(z_scores > 0, "High", "Low") }

head(data_tourism_hl[, grepl("_high$", names(data_tourism_hl))])
View(data_tourism_hl)


#### DATA_TOURISM_HL VERƒ∞SETƒ∞YLE PREDICTIONLAR 

# Gerekli k√ºt√ºphaneler
library(caret)
library(randomForest)
library(xgboost)
library(e1071)
library(pROC)


set.seed(1071)

# ‚úîÔ∏è 1. Veriyi Train ve Test olarak ayƒ±rma (Stratified Sampling)
index <- createDataPartition(data_tourism_hl$Food_Beverage_Level, p = 0.7, list = FALSE)
train_data <- data_tourism_hl[index, ]
test_data <- data_tourism_hl[-index, ]


# üîß Performans Deƒüerlendirme Fonksiyonu
evaluate_model <- function(model, test_data, target) {
  if (inherits(model, "train")) {
    predictions <- predict(model, test_data, type = "raw")
  } else if (inherits(model, "glm")) {
    predictions <- ifelse(predict(model, test_data, type = "response") > 0.5, "High", "Low")
  } else if (inherits(model, "randomForest")) {
    predictions <- predict(model, test_data)
  } else if (inherits(model, "xgb.Booster")) {
    predictions <- ifelse(predict(model, as.matrix(test_data[, c("TouristNumber", "Total_Income", "Year", "Quarter")])) > 0.5, "High", "Low")
  } else {
    predictions <- predict(model, test_data)
  }
  
  actuals <- test_data[[target]]
  conf_matrix <- confusionMatrix(factor(predictions, levels = c("High", "Low")), 
                                 factor(actuals, levels = c("High", "Low")))
  
  accuracy <- conf_matrix$overall["Accuracy"]
  precision <- conf_matrix$byClass["Pos Pred Value"]
  recall <- conf_matrix$byClass["Sensitivity"]
  f1_score <- 2 * ((precision * recall) / (precision + recall))
  
  return(c(Accuracy = accuracy, Precision = precision, Recall = recall, F1_Score = f1_score))
}

# üîß T√ºm Kategoriler ve Modeller i√ßin Otomatik Eƒüitim ve Deƒüerlendirme
targets <- c("Food_Beverage", "Accommodation", "Health", "Clothes", 
             "Carpet_Rug", "GSM_Expenditure", "Souvenirs", "Ind_Expenditure")

results <- data.frame(Category = character(), Model = character(),
                      Accuracy = numeric(), Precision = numeric(), 
                      Recall = numeric(), F1_Score = numeric())

for (col in targets) {
  target_col <- paste0(col, "_Level")
  print(paste("Training for:", target_col))
  
  # ‚úÖ Logistic Regression (Factor to Numeric)
  train_data[[target_col]] <- factor(train_data[[target_col]], levels = c("Low", "High"))
  test_data[[target_col]] <- factor(test_data[[target_col]], levels = c("Low", "High"))
  
  log_model <- glm(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")), 
                   data = train_data, family = "binomial")
  log_res <- evaluate_model(log_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "Logistic Regression", t(log_res)))

  #  Decision Tree
  tree_model <- train(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")), 
                      data = train_data, method = "rpart")
  tree_res <- evaluate_model(tree_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "Decision Tree", t(tree_res)))
  
  #  Random Forest
  rf_model <- randomForest(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")), 
                           data = train_data, ntree = 500)
  rf_res <- evaluate_model(rf_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "Random Forest", t(rf_res)))
  
  #  XGBoost
  dtrain <- xgb.DMatrix(as.matrix(train_data[, c("TouristNumber", "Total_Income", "Year", "Quarter")]), 
                        label = as.numeric(train_data[[target_col]] == "High"))
  dtest <- xgb.DMatrix(as.matrix(test_data[, c("TouristNumber", "Total_Income", "Year", "Quarter")]))
  xgb_model <- xgboost(data = dtrain, nrounds = 100, objective = "binary:logistic", verbose = 0)
  xgb_pred <- ifelse(predict(xgb_model, dtest) > 0.5, "High", "Low")
  xgb_res <- evaluate_model(xgb_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "XGBoost", t(xgb_res)))
  
  #  Naive Bayes
  nb_model <- naiveBayes(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")), 
                         data = train_data)
  nb_res <- evaluate_model(nb_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "Naive Bayes", t(nb_res)))
  
  #  KNN
  knn_model <- train(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")), 
                     data = train_data, method = "knn", tuneLength = 5)
  knn_res <- evaluate_model(knn_model, test_data, target_col)
  results <- rbind(results, data.frame(Category = col, Model = "KNN", t(knn_res)))
}

View(results)

#### TEST VERƒ∞Sƒ∞NDE TAHMƒ∞NLER

# Test Verisinde Tahmin Yapma
log_pred_prob <- predict(log_model, test_data, type = "response")  # Probability values
log_pred <- ifelse(log_pred_prob > 0.5, "High", "Low")  # High/Low tahmini

# Ger√ßek Deƒüerler ile Tahmin Sonu√ßlarƒ±nƒ± Kar≈üƒ±la≈ütƒ±rma
actuals <- test_data$Food_Beverage_Level

# Sonu√ßlarƒ± G√∂rselle≈ütirme (Confusion Matrix)
conf_matrix <- confusionMatrix(factor(log_pred, levels = c("Low", "High")), 
                               factor(actuals, levels = c("Low", "High")))

# Accuracy, Precision, Recall, F1-Score'larƒ± G√∂r√ºnt√ºleme
print(conf_matrix)

#  Logistic Regression Modelini Eƒüitme
log_model <- glm(Food_Beverage_Level ~ TouristNumber + Total_Income + Year + Quarter, 
                 data = train_data, family = "binomial")

#  Ger√ßek Deƒüerler
actuals <- test_data$Food_Beverage_Level

#  Tahmin Sonu√ßlarƒ±nƒ± Test Verisine Ekleyelim
test_data$Food_Beverage_Pred <- log_pred

#  Confusion Matrix Hesaplama
conf_matrix <- confusionMatrix(factor(log_pred, levels = c("Low", "High")), 
                               factor(test_data$Food_Beverage_Level, levels = c("Low", "High")))

#  TP, TN, FP, FN Hesaplama ve DataFrame Olarak G√∂sterme
confusion_df <- data.frame(
  Actual_Low = c(conf_matrix$table[1, 1], conf_matrix$table[1, 2]),
  Actual_High = c(conf_matrix$table[2, 1], conf_matrix$table[2, 2])
)
rownames(confusion_df) <- c("Predicted_Low", "Predicted_High")

# ‚úîÔ∏è Performans Metriklerini DataFrame Olarak G√∂sterme
performance_df <- data.frame(
  Metric = c("Accuracy", "Precision", "Recall", "F1-Score"),
  Value = c(
    round(conf_matrix$overall['Accuracy'], 4),
    round(conf_matrix$byClass['Pos Pred Value'], 4),
    round(conf_matrix$byClass['Sensitivity'], 4),
    round(2 * ((conf_matrix$byClass['Pos Pred Value'] * conf_matrix$byClass['Sensitivity']) /
                 (conf_matrix$byClass['Pos Pred Value'] + conf_matrix$byClass['Sensitivity'])), 4)
  )
)




#  Her Kategori i√ßin En Y√ºksek Doƒüruluƒüa Sahip Modeli Se√ßme
best_models <- results %>%
  group_by(Category) %>%
  slice_max(Accuracy.Accuracy, n = 1, with_ties = FALSE) %>%
  ungroup()

View(best_models)




library(caret)  # Confusion matrix i√ßin gerekli
library(dplyr)  # Verileri gruplamak i√ßin

#  Performans Sonu√ßlarƒ± Tablosu
all_predictions <- data.frame(Category = character(),
                              Actual = character(),
                              Predicted = character())

confusion_matrices <- list()  # Her kategori i√ßin confusion matrixleri kaydet

for (i in 1:nrow(best_models)) {
  category <- best_models$Category[i]
  best_model <- best_models$Model[i]
  
  target_col <- paste0(category, "_Level")
  
  print(paste("Testing with Best Model for:", category, "-", best_model))
  
  # Modeli se√ßme ve tahmin yapma
  if (best_model == "Logistic Regression") {
    model <- glm(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")),
                 data = train_data, family = "binomial")
    pred_probs <- predict(model, test_data, type = "response")
    predictions <- ifelse(pred_probs > 0.5, "High", "Low")
    
  } else if (best_model == "Decision Tree") {
    model <- train(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")),
                   data = train_data, method = "rpart")
    predictions <- predict(model, test_data)
    
  } else if (best_model == "Random Forest") {
    model <- randomForest(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")),
                          data = train_data, ntree = 500)
    predictions <- predict(model, test_data)
    
  } else if (best_model == "XGBoost") {
    dtrain <- xgb.DMatrix(as.matrix(train_data[, c("TouristNumber", "Total_Income", "Year", "Quarter")]),
                          label = as.numeric(train_data[[target_col]] == "High"))
    dtest <- xgb.DMatrix(as.matrix(test_data[, c("TouristNumber", "Total_Income", "Year", "Quarter")]))
    model <- xgboost(data = dtrain, nrounds = 100, objective = "binary:logistic", verbose = 0)
    predictions <- ifelse(predict(model, dtest) > 0.5, "High", "Low")
    
  } else if (best_model == "Naive Bayes") {
    model <- naiveBayes(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")),
                        data = train_data)
    predictions <- predict(model, test_data)
    
  } else if (best_model == "KNN") {
    model <- train(as.formula(paste(target_col, "~ TouristNumber + Total_Income + Year + Quarter")),
                   data = train_data, method = "knn", tuneLength = 5)
    predictions <- predict(model, test_data)
  }
  
  # Test verisine tahminleri ekleme
  test_data[[paste0(category, "_Pred")]] <- predictions
  
  # Confusion Matrix Hesaplama
  actuals <- test_data[[target_col]]
  conf_matrix <- confusionMatrix(factor(predictions, levels = c("Low", "High")), 
                                 factor(actuals, levels = c("Low", "High")))
  confusion_matrices[[category]] <- conf_matrix
  
  # Sonu√ßlarƒ± kaydetme
  all_predictions <- rbind(all_predictions, 
                           data.frame(Category = category,
                                      Actual = actuals,
                                      Predicted = predictions))
}
View(test_data) #### t√ºm veriler leveller ve predler dahil olan dataset

View(all_predictions)

# Confusion Matrices'i G√∂r√ºnt√ºleme
confusion_matrices  # Her kategori i√ßin Confusion Matrix



###### VISUALIZATIOINS

# Turist Sayƒ±sƒ± ve Toplam Gelir ƒ∞li≈ükisi
library(ggplot2)
ggplot(data_tourism, aes(x = TouristNumber, y = Total_Income)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Toplam Gelir ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Toplam Gelir") +
  theme_minimal()



# Turist Sayƒ±sƒ± ve Gƒ±da-ƒ∞√ßecek Harcamasƒ± ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y = Food_Beverage)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Gƒ±da-ƒ∞√ßecek Harcamasƒ± ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Gƒ±da-ƒ∞√ßecek Harcamasƒ±") +
  theme_minimal()

# Turist Sayƒ±sƒ± ve Konaklama Harcamasƒ± ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y = Accommodation)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Konaklama Harcamasƒ± ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Konaklama Harcamasƒ±") +
  theme_minimal()


# Turist Sayƒ±sƒ± ve Ind_Expenditure ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y = Ind_Expenditure)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Gƒ±da-ƒ∞√ßecek Harcamasƒ± ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Ind_ExpenditureHarcamasƒ±") +
  theme_minimal()


# Turist Sayƒ±sƒ± ve Health Harcamasƒ± ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y =Health)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Gƒ±da-ƒ∞√ßecek Harcamasƒ± ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Gƒ±da-ƒ∞√ßecek Harcamasƒ±") +
  theme_minimal()


# Turist Sayƒ±sƒ± ve Carpet_Rug Harcamasƒ± ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y =Carpet_Rug)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve Gƒ±da-ƒ∞√ßecek Harcamasƒ± ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "Carpet_Rug") +
  theme_minimal()


# Turist Sayƒ±sƒ± ve GSM_Expenditure Harcamasƒ± ƒ∞li≈ükisi
ggplot(data_tourism, aes(x = TouristNumber, y =GSM_Expenditure)) +
  geom_point(aes(color = Year)) +
  geom_smooth(method = "lm", col = "red") +
  labs(title = "Turist Sayƒ±sƒ± ve GSM_Expenditure ƒ∞li≈ükisi", x = "Turist Sayƒ±sƒ±", y = "GSM_Expenditure") +
  theme_minimal()



# Yƒ±l Bazƒ±nda Kategori Oranlarƒ± --- bunda IndExpend √ßƒ±kar
category_ratios <- colMeans(data_train2[, output_features] / data_train2$Total_Income, na.rm = TRUE)
category_ratios_df <- data.frame(Category = names(category_ratios), Ratio = category_ratios)

ggplot(category_ratios_df, aes(x = Category, y = Ratio, fill = Category)) +
  geom_bar(stat = "identity") +
  labs(title = "Yƒ±l Bazƒ±nda Kategori Oranlarƒ±", x = "Kategori", y = "Oran") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



# Z-Skorlarƒ± ile Kategorik Etiketler *----- bunu diƒüerleri i√ßin de yap
ggplot(data_tourism_hl, aes(x = Food_Beverage_Level, fill = Food_Beverage_Level)) +
  geom_bar() +
  labs(title = "Gƒ±da-ƒ∞√ßecek Harcamasƒ± Y√ºksek/D√º≈ü√ºk Daƒüƒ±lƒ±mƒ±", x = "Kategori Seviye", y = "Frekans") +
  theme_minimal()



###### CONFUSION MATRIX G√ñRSELLE≈ûTƒ∞RMESƒ∞ BUNU HEPSƒ∞ ƒ∞√áƒ∞N YAPP
# Confusion Matrix Sonu√ßlarƒ±
conf_matrix <- confusionMatrix(factor(test_data$Food_Beverage_Pred, levels = c("Low", "High")), 
                               factor(test_data$Food_Beverage_Level, levels = c("Low", "High")))
# Confusion Matrix G√∂rselle≈ütirmesi
library(caret)
library(ggplot2)

# Confusion Matrix Tablosunu DataFrame'e D√∂n√º≈üt√ºrme
confusion_df <- as.data.frame(conf_matrix$table)
colnames(confusion_df) <- c("Actual", "Predicted", "Freq")

# G√∂rselle≈ütirme
ggplot(confusion_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile(color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = Freq), vjust = 1.5, color = "black", size = 5) +
  labs(
    title = "Confusion Matrix: Food & Beverage Predicted vs Actual",
    x = "Predicted", 
    y = "Actual"
  ) +
  theme_minimal()



# Performans Sonu√ßlarƒ±nƒ± Bar Plot Olarak G√∂rselle≈ütirme
ggplot(results, aes(x = Category, y = Accuracy.Accuracy, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Model Performansƒ±: Kategorik Sƒ±nƒ±flandƒ±rma", x = "Kategori", y = "Doƒüruluk") + 
  scale_fill_brewer(palette = "RdYlBu") + 
  theme_minimal()



data_train5 = data_tourism

# Yƒ±l ve √áeyrek Bilgilerini Birle≈ütiriyoruz
data_train5$Date <- as.Date(paste(data_train5$Year, (data_train5$Quarter - 1) * 3 + 1, "01", sep = "-"))

# Tarihe G√∂re Sƒ±ralama
data_train5 <- data_train5 %>% arrange(Date)
View(data_train5)



# Zaman Serisi Grafiƒüi: Turist Sayƒ±sƒ± ve Gelir
ggplot(data_train5, aes(x = Date)) +
  geom_line(aes(y = TouristNumber, color = "Turist Sayƒ±sƒ±"), size = 1) +
  geom_line(aes(y = Total_Income / 1000, color = "Turizm Geliri (Bin TL)"), size = 1) +
  labs(title = "Turist Sayƒ±sƒ± ve Turizm Geliri: Zaman Serisi", 
       x = "Yƒ±l", 
       y = "Deƒüer") +
  scale_color_manual(values = c("Turist Sayƒ±sƒ±" = "darkgreen", "Turizm Geliri (Thousand Dollar)" = "darkblue")) +
  theme_minimal()

# √áeyrek Bazlƒ± Boxplot
ggplot(data_train5, aes(x = as.factor(Quarter), y = Total_Income / 1000, fill = as.factor(Quarter))) +
  geom_boxplot() +
  labs(title = "√áeyreklere G√∂re Turizm Geliri Daƒüƒ±lƒ±mƒ±", 
       x = "√áeyrek (Quarter)", 
       y = "Turizm Geliri (Bin TL)") +
  theme_minimal()

install.packages("stl")
# Turizm Gelirleri ƒ∞√ßin Zaman Serisi Nesnesi
income_ts <- ts(data_train5$Total_Income, start = c(min(data$Year), min(data$Quarter)), frequency = 4)

# Sezonluk ve Trend Analizi
decomp <- stl(income_ts, s.window = "periodic")
autoplot(decomp) + 
  labs(title = "Turizm Geliri Sezonluk ve Trend Analizi") +
  theme_minimal()
